{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "first.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ive9tPJ4PEtq",
        "colab_type": "text"
      },
      "source": [
        "**Classify insults using glove and attention**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuOp-KBo6zj4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "78ae787b-2a9d-449d-e5c2-03e4bdb6a540"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount = True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tV2BnA6Z7Ubj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_path = 'gdrive/My Drive/Colab/insult/'\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "train_df = pd.read_csv(dataset_path + \"train_text.csv\", encoding = 'latin-1')\n",
        "test_df = pd.read_csv(dataset_path + \"test_text.csv\", encoding = 'latin-1')\n",
        "train_id, X_train, y_train = train_df['id'], train_df['Comment'], train_df['Target']\n",
        "test_id, X_test = test_df['id'], test_df['Comment']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hO4fjy1TR6b7",
        "colab_type": "text"
      },
      "source": [
        "**Standard preprocessing applied** (some have been commented based on results and observations)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_5OQZOP7jjp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b9c633e8-2b9f-4d59-932b-681b4c63bfd7"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "import string\n",
        "nltk.download('punkt')\n",
        "X_train_mod, y_train_mod = [], []\n",
        "X_test_mod= []\n",
        "words = []\n",
        "table = str.maketrans(string.punctuation, ' '*len(string.punctuation))\n",
        "for ind, review in enumerate(X_train):\n",
        "  try:\n",
        "    #review = cleanData(review)\n",
        "    word_review = word_tokenize(review)\n",
        "    \n",
        "    word_review = [w.translate(table) for w in word_review]\n",
        "    #word_review = [w for w in word_review if w.isalpha()]\n",
        "    #word_review = [w for w in word_review if w not in stop_words]\n",
        "    word_review = [w.lower() for w in word_review]\n",
        "    #word_review = [lmtzr.lemmatize(w) for w in word_review]\n",
        "    #word_review = list(set(word_review))\n",
        "    text_joined = ' '.join(word_review)\n",
        "    X_train_mod.append(text_joined)\n",
        "    y_train_mod.append(y_train[ind])\n",
        "    \n",
        "    words += word_review\n",
        "  except:\n",
        "    \n",
        "    continue\n",
        "for ind, review in enumerate(X_test):\n",
        "  try:\n",
        "    #review = cleanData(review)\n",
        "    word_review = word_tokenize(review)\n",
        "    \n",
        "    word_review = [w.translate(table) for w in word_review]\n",
        "    #word_review = [w for w in word_review if w.isalpha()]\n",
        "    #word_review = [w for w in word_review if w not in stop_words]\n",
        "    word_review = [w.lower() for w in word_review]\n",
        "    #word_review = [lmtzr.lemmatize(w) for w in word_review]\n",
        "    #word_review = list(set(word_review))\n",
        "    text_joined = ' '.join(word_review)\n",
        "    X_test_mod.append(text_joined)\n",
        "    #y_test_mod.append(y_test[ind])\n",
        "    words += word_review\n",
        "  except:\n",
        "    continue\n",
        "    \n",
        "X_total = X_train_mod + X_test_mod"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvFpcWkOcr-F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0c9ec454-75f4-4092-d81d-2642a90c38ca"
      },
      "source": [
        "print(len(X_test_mod))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "73556\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTw6fBkWSILM",
        "colab_type": "text"
      },
      "source": [
        "**Using Glove 300d**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0B8qGlf732F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding = {}\n",
        "f = open(dataset_path + \"glove.840B.300d.txt\")\n",
        "\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    try:\n",
        "      coefs = np.asarray(values[1:], dtype='float32')\n",
        "      embedding[word] = coefs\n",
        "    except:\n",
        "      continue\n",
        "    \n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6wrWwK6Ugxj",
        "colab_type": "text"
      },
      "source": [
        "**Keras Processing and glove vectorization**\n",
        "The most notable point here is we have padded the sequences in two ways: Pre and post. We are going to use them in our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAqGYC3y78J4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "25768d7f-5f6d-4e25-81e6-f9080e5bee87"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "#max_len = max(len(l.split()) for l in X_total)\n",
        "max_len = 200\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_total)\n",
        "sequences = tokenizer.texts_to_sequences(X_train_mod)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "print(len(word_index))\n",
        "\n",
        "review_pad = pad_sequences(sequences, maxlen = max_len)\n",
        "review_pad_post = pad_sequences(sequences, maxlen=max_len,padding='post', truncating='post')\n",
        "print(review_pad.shape)\n",
        "print(review_pad_post.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "251917\n",
            "(101575, 200)\n",
            "(101575, 200)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1gAVBdx8AZp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train_mod = np.asarray(y_train_mod).reshape(len(y_train_mod), 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_6WQ2az8DEe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a044e65e-82f7-42e7-fa0a-d242fb29eb61"
      },
      "source": [
        "num_words = len(word_index) + 1\n",
        "embedding_matrix = np.zeros((num_words, 300))\n",
        "for word, i in word_index.items():\n",
        "  if i > num_words:\n",
        "    continue\n",
        "  embedding_vector = embedding.get(word)\n",
        "  if embedding_vector is not None:\n",
        "    embedding_matrix[i] = embedding_vector\n",
        "    \n",
        "print(num_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "251918\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wUrhSRXWXHe",
        "colab_type": "text"
      },
      "source": [
        "**The Central Model**\n",
        "\n",
        "Based on the pre and post padding, we have two branches now. For each branch, we send the input layer through an LSTM layer with dropout before sending it to the attention block. Post this procedure for each block, we concatenate the blocks, flatten them, add a dense layer, and finally the output layer is obtained."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUZnqWBb8Fjv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from keras.initializers import Constant\n",
        "\n",
        "TIME_STEPS = max_len\n",
        "INPUT_DIM = max_len\n",
        "\n",
        "def attention_3d_block(inputs):\n",
        "    # inputs.shape = (batch_size, time_steps, input_dim)\n",
        "    input_dim = int(inputs.shape[2])//2\n",
        "    a = Permute((2, 1))(inputs)\n",
        "    a = Dense(TIME_STEPS*2, activation='relu')(a)\n",
        "    a = Dense(TIME_STEPS, activation='softmax')(a)\n",
        "    a_probs = Permute((2, 1))(a)\n",
        "    output_attention_mul = Multiply()([inputs, a_probs])\n",
        "    #output_attention_mul = merge([inputs, a_probs], name='attention_mul', mode='mul')\n",
        "    return output_attention_mul\n",
        "\n",
        "\n",
        "def model_attention_applied_after_lstm():\n",
        "    input_pre = Input(shape= (INPUT_DIM,))\n",
        "    input_post = Input(shape= (INPUT_DIM,))\n",
        "    lstm_units = 32\n",
        "    embedding_layer = Embedding(num_words,\n",
        "                                300,\n",
        "                                embeddings_initializer = Constant(embedding_matrix),\n",
        "                                input_length = max_len,\n",
        "                                trainable=False)\n",
        "    \n",
        "    inputs_1 = embedding_layer(input_pre)\n",
        "    inputs_1 = SpatialDropout1D(0.25)(inputs_1)\n",
        "    lstm_out_1 = Bidirectional(CuDNNLSTM(lstm_units,return_sequences=True))(inputs_1)\n",
        "    lstm_out_1 = Dropout(0.5)(lstm_out_1)\n",
        "    x1 = attention_3d_block(lstm_out_1)\n",
        "\n",
        "    inputs_2 = embedding_layer(input_post)\n",
        "    inputs_2 = SpatialDropout1D(0.25)(inputs_2)\n",
        "    lstm_out_2 = Bidirectional(CuDNNLSTM(lstm_units,return_sequences=True))(inputs_2)\n",
        "    lstm_out_2 = Dropout(0.5)(lstm_out_2)\n",
        "    x2 = attention_3d_block(lstm_out_2)\n",
        "\n",
        "    x = concatenate([x1, x2])\n",
        "    x = Flatten()(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    preds = Dense(1, activation='sigmoid')(x)\n",
        "    model = Model(inputs=[input_pre, input_post], outputs=preds)\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZhDuijT8MP9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m = model_attention_applied_after_lstm()\n",
        "\n",
        "#m.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "print(m.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5Wq8WDj8Pxh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "94aead5d-ceca-4a49-d309-1e64772286d6"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(review_pad, \n",
        "                                                    y_train_mod, test_size=0.1,\n",
        "                                                    random_state=42,\n",
        "                                                    stratify=y_train_mod)\n",
        "X_train_p, X_test_p, y_train_p, y_test_p = train_test_split(review_pad_post, \n",
        "                                                    y_train_mod, test_size=0.1,\n",
        "                                                    random_state=42,\n",
        "                                                    stratify=y_train_mod)\n",
        "\n",
        "print(y_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(91417, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTV4zffWIZPO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "checkpoint_path = dataset_path + \"model-{epoch:02d}.h5\"\n",
        "\n",
        "cp_callback = ModelCheckpoint(checkpoint_path, verbose=1,\n",
        "                              save_best_only=True,\n",
        "                              monitor='val_loss')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gD3qWzHl8VQ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m.fit([X_train,X_train_p], y_train, batch_size = 128, epochs = 10,\n",
        "      validation_data = ([X_test,X_test_p], y_test),\n",
        "          callbacks = [], verbose = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_wXExNw9lBw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "8971b20d-e3fe-4d19-ef3b-7e2b8b2f5ba0"
      },
      "source": [
        "sequences = tokenizer.texts_to_sequences(X_test_mod)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "print(len(word_index))\n",
        "\n",
        "test_pad = pad_sequences(sequences, maxlen = max_len)\n",
        "test_pad_post = pad_sequences(sequences, maxlen=max_len,padding='post', truncating='post')\n",
        "print(test_pad.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "251917\n",
            "(73556, 200)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0yGsv6rRIj_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "model = load_model(\"gdrive/My Drive/Colab/insult/model-07.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6YITOc-RRvF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a7ce7aae-a7fe-496a-83e8-994450ec4f66"
      },
      "source": [
        "output = model.predict([test_pad,test_pad_post], verbose=1, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "73556/73556 [==============================] - 13s 170us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q47WfcM1RXXW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output = [l[0] for l in output]\n",
        "output = list(output)\n",
        "out_df = pd.DataFrame(list(zip(test_id, output)), columns =['id', 'Prediction'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RbXeUuaRgg4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(out_df)\n",
        "out_df.to_csv(\"output_attn_1.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swgXa3oDStd-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}